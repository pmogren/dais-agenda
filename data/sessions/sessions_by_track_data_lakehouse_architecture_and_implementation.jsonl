{"session_id": "practitioners-guide-databricks-serverless", "title": "A Practitioner\u2019s Guide to Databricks Serverless", "track": "DATA LAKEHOUSE ARCHITECTURE AND IMPLEMENTATION", "level": "BEGINNER", "type": "BREAKOUT", "industry": "ENTERPRISE TECHNOLOGY", "technologies": ["DATABRICKS WORKFLOWS", "DLT"], "duration": "40 MIN", "experience": "IN PERSON", "areas_of_interest": ["Analytics", "Data Engineering", "Data Pipeline"], "speakers": ["Product Specialist, Databricks"], "schedule": {"day": "", "room": "", "start_time": "", "end_time": ""}, "description": "Databricks Serverless revolutionizes data engineering and analytics by eliminating the complexities of infrastructure management. This talk will provide an overview of this powerful serverless compute option, highlighting how it enables practitioners to focus solely on building robust data pipelines. We'll explore the core benefits, including automatic scaling, cost optimization and seamless integration with the Databricks ecosystem. Learn how serverless workflows simplify the orchestration of various data tasks, from ingestion to dashboards, ultimately accelerating time-to-insight and boosting productivity. This session is ideal for data engineers, data scientists and analysts looking to leverage the agility and efficiency of serverless computing in their data workflows. /Product Specialist"}
{"session_id": "prescription-success-leveraging-dabs-faster-deployment-and-better", "title": "A Prescription for Success: Leveraging DABs for Faster Deployment and Better Patient Outcomes", "track": "DATA LAKEHOUSE ARCHITECTURE AND IMPLEMENTATION", "level": "INTERMEDIATE", "type": "BREAKOUT", "industry": "HEALTH AND LIFE SCIENCES", "technologies": ["DATABRICKS WORKFLOWS", "UNITY CATALOG"], "duration": "40 MIN", "experience": "IN PERSON", "areas_of_interest": ["AI", "Analytics"], "speakers": ["Principal Data Engineer, Health Catalyst"], "schedule": {"day": "", "room": "", "start_time": "", "end_time": ""}, "description": "Health Catalyst (HCAT) transformed its CI/CD strategy by replacing a rigid, internal deployment tool with Databricks Asset Bundles (DABs), unlocking greater agility and efficiency. This shift streamlined deployments across both customer workspaces and HCAT's core platform, accelerating time to insights and driving continuous innovation. By adopting DABs, HCAT ensures feature parity, standardizes metric stores across clients, and rapidly delivers tailored analytics solutions. Attendees will gain practical insights into modernizing CI/CD pipelines for healthcare analytics, leveraging Databricks to scale data-driven improvements. HCAT's next-generation platform, Health Catalyst Ignite\u2122, integrates healthcare-specific data models, self-service analytics, and domain expertise\u2014powering faster, smarter decision-making. /Sr. Solutions Architect\nDatabricks /Principal Data Engineer"}
{"session_id": "unified-solution-data-management-and-model-training-apache-iceberg-and", "title": "A Unified Solution for Data Management and Model Training With Apache Iceberg and Mosaic Streaming", "track": "DATA LAKEHOUSE ARCHITECTURE AND IMPLEMENTATION", "level": "ADVANCED", "type": "BREAKOUT", "industry": "MEDIA AND ENTERTAINMENT, PUBLIC SECTOR", "technologies": ["APACHE ICEBERG", "MOSAIC AI"], "duration": "40 MIN", "experience": "IN PERSON", "areas_of_interest": ["AI", "Machine Learning", "Scala", "Streaming"], "speakers": ["machine learning system engineer, ByteDance"], "schedule": {"day": "", "room": "", "start_time": "", "end_time": ""}, "description": "This session introduces ByteDance\u2019s challenges in data management and model training, and addresses them by Magnus (enhanced Apache Iceberg) and Byted Streaming (customized Mosaic Streaming). Magnus uses Iceberg\u2019s branch/tag to manage massive datasets/checkpoints efficiently. With enhanced metadata and a custom C++ data reader, Magnus achieves optimal sharding, shuffling and data loading. Flexible table migration, detailed metrics and built-in full-text indexes on Iceberg tables further ensure training reliability. When training with ultra-large datasets, ByteDance faced scalability and performance issues. Given Streaming's scalability in distributed training and good code structure, the team chose and customized it to resolve challenges like slow startup, high resource consumption, and limited data source compatibility. In this session, we will explore Magnus and Byted Streaming, discuss their enhancements and demonstrate how they enable efficient and robust distributed training. /Infrastructure Engineer\nByteDance /machine learning system engineer"}
