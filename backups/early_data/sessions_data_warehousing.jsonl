{"id":"D25B1732","title":"A Japanese Mega-Bank\u2019s Journey to a Modern, GenAI-Powered, Governed Data Platform","description":"<p>SMBC-AD, a major Japanese multinational financial services institution, has embarked on an initiative to build a GenAI-powered, modern and well-governed cloud data platform on Azure\/Databricks. This initiative aims to build an enterprise data foundation encompassing loans, deposits, securities, derivatives, and other data domains.<\/p><p>\u00a0<\/p><p>Its primary goals are:<\/p><ul>\t<li>To decommission legacy data platforms and reduce data sprawl by migrating 20+ core banking systems to a multi-tenant Azure Databricks architecture<\/li>\t<li>To leverage Databrick\u2019s delta-share capabilities to address SMBC\u2019s unique global footprint and data sharing needs<\/li>\t<li>To govern data by design using Unity Catalog<\/li>\t<li>To achieve global adoption of the frameworks, accelerators, architecture and tool stack to support similar implementations across EMEA<\/li><\/ul><p>Deloitte and SMBC leveraged the Brickbuilder asset \u201cData as a Service for Banking\u201d to accelerate this highly strategic transformation.<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Financial Services"],"category":["Apache Spark, DLT, Unity Catalog"],"areas_of_interest":["Customer Data Platform, Generative AI (LLMs), Migrations"],"delivery":["In Person"],"speakers":[{"name":"Anshul Wadhawan","company":"Deloitte Consulting LLP","job_title":"Principal","bio":null,"image":{}},{"name":"Gordon Wilson","company":"SMBC","job_title":"Chief Information Officer","bio":"Gordon (Gordo) Wilson is the Chief Information Officer for SMBC Group in the Americas. He leads the technology organization across the firm, focusing on both daily technical operations and strategic planning and execution in alignment with overall business priorities.<br \/>\n<br \/>\nA career leader and financial services senior executive, Gordo joined the company in February 2020 as the Americas Chief Data Officer to lead the development and execution of an enterprise-wide data strategy, with a focus on data management and data governance. Gordo was named Chief Information Officer in July 2021.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/Gordon%2520Wilson_1738342492318001xTAC.jpg?h=f604ef3e&itok=qQLGIa5u","alt":"Gordon Wilson"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/japanese-mega-banks-journey-modern-genai-powered-governed-data-platform","alias":"\/data-ai-summit-2025\/session\/japanese-mega-banks-journey-modern-genai-powered-governed-data-platform","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.533655+00:00"}
{"id":"D25B3181DBX","title":"Accelerating Analytics: Integrating BI Tools to Databricks SQL","description":"<p>Did you know that you can integrate with your favorite BI tools directly from Databricks SQL? You don\u2019t even need to stand up an additional warehouse. This session shows the integrations with Microsoft Power Platform, Power BI, Tableau, Sigma and Looker so you can have a seamless integration experience. Directly connect your Databricks workspace with Fabric and Power BI workspaces or Tableau to publish and sync data models, with defined primary and foreign keys, between the two platforms.<\/p>","track":"Data Warehousing","level":"Beginner","type":"Breakout","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX), Getting started with Databricks"],"delivery":["In Person"],"speakers":[{"name":"Fuat Can Efeoglu","company":"Databricks","job_title":"Sr. Staff Product Manager","bio":null,"image":{}},{"name":"Toussaint Webb","company":"Databricks","job_title":"Product Manager","bio":"Toussaint Webb is a Product Manager at Databricks, where he leads efforts to improve connectivity and user experience with ISV technology partners. Previously, he was a Product Manager at LinkedIn, where he built advertiser safety tools and content understanding and personalization systems for the LinkedIn Feed. Toussaint holds a B.S. in Computer Science from Princeton University.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/touissant_headshot_1744830087019001lKVA.png?h=14d55bae&itok=aNb3h4VP","alt":"Toussaint Webb"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/accelerating-analytics-integrating-bi-tools-databricks-sql","alias":"\/data-ai-summit-2025\/session\/accelerating-analytics-integrating-bi-tools-databricks-sql","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.533677+00:00"}
{"id":"D25L2101","title":"Accelerating Data Transformation: Best Practices for Governance, Agility and Innovation","description":"<p>In this session, we will share NCS\u2019s approach to implementing a Databricks Lakehouse architecture, focusing on key lessons learned and best practices from our recent implementations. By integrating Databricks SQL Warehouse, the DBT Transform framework and our innovative test automation framework, we\u2019ve optimized performance and scalability, while ensuring data quality. We\u2019ll dive into how Unity Catalog enabled robust data governance, empowering business units with self-serve analytical workspaces to create insights while maintaining control. Through the use of solution accelerators, rapid environment deployment and pattern-driven ELT frameworks, we\u2019ve fast-tracked time-to-value and fostered a culture of innovation. Attendees will gain valuable insights into accelerating data transformation, governance and scaling analytics with Databricks.<\/p>","track":"Data Warehousing","level":"Beginner","type":"Lightning Talk","industry":["Energy and Utilities, Public Sector, Financial Services"],"category":["Delta Lake, Databricks SQL, Unity Catalog"],"areas_of_interest":["ETL, SQL, Thought Leadership"],"delivery":["In Person"],"speakers":[{"name":"Kevin Wilson","company":"NCS Australia","job_title":"Practice Director, Data & AI","bio":"Kevin Wilson is the Practice Director for Data & AI at NCS Australia, leading a national team of nearly 200 consultants in Data Strategy, Governance, Architecture, Engineering, and AI. <br \/>\n<br \/>\nWith over 25 years of experience in international IT consultancies across the UK, Ireland, and Australia, Kevin has successfully delivered end-to-end data platforms and BI Solutions across diverse industries, including finance, retail, utilities, and government.<br \/>\n<br \/>\nNCS, headquartered in Singapore, is a leading technology services firm with over 40 years of experience driving digital transformation across Asia Pacific.  NCS combines deep domain expertise and cutting-edge innovation to help governments and enterprises harness technology to advance communities.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/Kevin%2520Wilson%2520Profile%25201_1745817235038001Z5eD.png?h=a77b4edb&itok=eAo-qSDb","alt":"Kevin Wilson"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"20","path":"\/session\/accelerating-data-transformation-best-practices-governance-agility-and","alias":"\/data-ai-summit-2025\/session\/accelerating-data-transformation-best-practices-governance-agility-and","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.533684+00:00"}
{"id":"D25B3177DBX","title":"AI Meets SQL: Leverage GenAI at Scale to Enrich Your Data","description":"<p>Integrating AI into existing data workflows can be challenging, often requiring specialized knowledge and complex infrastructure. In this session, we'll share how SQL users can leverage AI\/ML to access large language models (LLMs) and traditional machine learning directly from within SQL, simplifying the process of incorporating AI into data workflows. We will demonstrate how to use Databricks SQL for natural language processing, traditional machine learning, retrieval augmented generation and more. You'll learn about best practices and see examples of solving common use cases such as opinion mining, sentiment analysis, forecasting and other common AI\/ML tasks.<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Enterprise Technology"],"category":["Databricks SQL, Mosaic AI"],"areas_of_interest":["Databricks Experience (DBX), Generative AI (LLMs)"],"delivery":["In Person"],"speakers":[{"name":"Alexander Lichen","company":"Databricks","job_title":"Sr. Product Manager","bio":null,"image":{}},{"name":"Amir Hormati","company":"databricks","job_title":"swe","bio":null,"image":{}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/ai-meets-sql-leverage-genai-scale-enrich-your-data","alias":"\/data-ai-summit-2025\/session\/ai-meets-sql-leverage-genai-scale-enrich-your-data","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.533733+00:00"}
{"id":"D25B3187DBX","title":"Busting Data Modeling Myths: Truths and Best Practices for Data Modeling in the Lakehouse","description":"<p>Unlock the truth behind data modeling in Databricks. This session will tackle the top 10 myths surrounding relational and dimensional data modeling. Attendees will gain a clear understanding of what Databricks Lakehouse truly supports today, including how to leverage primary and foreign keys, identity columns for surrogate keys, column-level data quality constraints and much more. This session will talk through the lens of medallion architecture, explaining how to implement data models across bronze, silver, and gold tables. Whether you\u2019re migrating from a legacy warehouse or building new analytics solutions, you\u2019ll leave equipped to fully leverage Databricks\u2019 capabilities, and design scalable, high-performance data models for enterprise analytics.<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX)"],"delivery":["In Person"],"speakers":[{"name":"Kyle Hale","company":"Databricks","job_title":"DBSQL Product Specialist","bio":"Kyle Hale\u2019s journey into data and analytics began at age 8 when he created his first database to analyze baseball statistics, and hasn\u2019t stopped yet. He\u2019s a 20 year veteran of the data warehousing and BI space, having worn every hat from report development, modeling, and performance tuning to architecture, strategy, and governance. Having been a trusted advisor to well over 1,000 organizations big and small: Kyle has seen things.His proudest moment is being recognized by his peers at Databricks as a Data and Analytics SME - game knows game.When he\u2019s not secretly plotting like all good BI professionals to kill Excel once and for all, he enjoys crafting synth pop soundtracks to imaginary movies, solving chess puzzles, and roaming the countryside with his wife and 4 kids in search of cool museums and awesome fried chicken. He is also an avid collector of dad jokes.","image":{}},{"name":"Shannon Barrow","company":"Databricks","job_title":"Practice Lead","bio":"Shannon has spent the last 5 years at Databricks helping enterprise customers modernize their analytics platforms to maximize value from their data and drive down the total cost of ownership.  Specializing in performance for data engineering and SQL consumption, he is a leading SME in benchmarking and POC efforts across Enterprise North America.  Before joining Databricks in 2019, he was a Principal in Accenture's Innovation and Thought Leadership team.  Shannon has a Masters in Computer Science from Georgia Tech and 2 Bachelor Degrees from Florida State University.","image":{}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/busting-data-modeling-myths-truths-and-best-practices-data-modeling","alias":"\/data-ai-summit-2025\/session\/busting-data-modeling-myths-truths-and-best-practices-data-modeling","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.533944+00:00"}
{"id":"D25B3182DBX","title":"Comprehensive Data Warehouse Migrations to Databricks SQL","description":"<p>Databricks has a free, comprehensive solution for migrating legacy data warehouses from a wide range of source systems. See how we accelerate migrations from legacy data warehouses to Databricks SQL, achieving 50% faster migration than traditional methods.\u00a0<\/p><p>\u00a0<\/p><p>We'll cover the tool\u2019s automated migration process:<\/p><ul>\t<li>Discovery: Source system profiling<\/li>\t<li>Assessment: Legacy code analysis<\/li>\t<li>Conversion: Advanced code transpilation<\/li>\t<li>Reconciliation: Data validation<\/li><\/ul><p>\u00a0<\/p><p>This comprehensive approach increases the predictability of migration projects, allowing businesses to plan and execute migrations with greater confidence.<\/p>","track":"Data Warehousing","level":"Beginner","type":"Breakout","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX), Migrations"],"delivery":["In Person"],"speakers":[{"name":"Sundar Shankar","company":"Databricks","job_title":"Sr Specialist Solutions Architect","bio":"Sundar Shankar is a seasoned Architect, engineer and consultant at Databricks, renowned for his expertise in building large-scale data applications. Sundar has empowered some of the world's leading organisations to solve complex challenges using insights and analytics powered by reliable data systems.<br \/>\nDriven by firsthand experience with the challenges and complexities of modernising legacy data applications, Sundar is dedicated to building a scalable platform that accelerates and simplifies migrations to Databricks. His mission is to empower organisations to seamlessly transition to modern, high-performance data solutions.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/Sundar%2520Alternate%2520Profile_1744868413295001bGtz.png?h=a7ffc51c&itok=OW0kqFe3","alt":"Sundar Shankar"}},{"name":"Simon Eligulashvili","company":"Databricks","job_title":"Lead Specialist Solutions Architect","bio":"Simon Eligulashvili is a senior IT executive with over 25 years of experience in architecting, managing, and delivering innovative technology solutions with special focus in the areas of data warehousing and code migrations.  Simon joined Databricks in January 2025 via acquisition of BladeBridge, where he was a technical co-founder and a principal architect for code migration acceleration products.  Prior to establishing BladeBridge, Simon headed a consulting and software company that served leading organizations in finance, insurance, retail, and other industries, enabling efficient implementations of large-scale data warehouses and datamarts.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/Simon__Eligulashvili_1746109744785001oxxl.jpg?h=24cab724&itok=DksAMVi-","alt":"Simon Eligulashvili"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/comprehensive-data-warehouse-migrations-databricks-sql","alias":"\/data-ai-summit-2025\/session\/comprehensive-data-warehouse-migrations-databricks-sql","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.533975+00:00"}
{"id":"D25B3175DBX","title":"Cooking With SQL: From Ingredients to Insights With Minimal Prep","description":"<p>In this session we\u2019ll dive into the SQL kitchen and use a combination of SQL staples and nouvelle cuisine such as recursive queries, temporary tables, and stored procedures. We\u2019ll leave you with well-scripted recipes to execute immediately or store for later consumption in your Unity Catalog. Think of this session as building your go-to cookbook of SQL techniques. Bon app\u00e9tit!<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX), SQL"],"delivery":["In Person"],"speakers":[{"name":"Serge Rielau","company":"Databricks","job_title":"Principal Software Engineer","bio":"Serge got into software as a teenager when one still memorized hex-arithmetic. He studied at TU Kaiserslautern, Germany and got into databases at IBM in 1996. After some 15 years as SQL architect and a detour through Openpages he did a 5 year stint at Salesforce working on a PostgreSQL fork. Since 4 years Serge holds down a job as SQL Tsar, hobby doc writer, and error message wrangler at Databricks.","image":{}},{"name":"Fabien Contaminard","company":"Databricks","job_title":"Sr. Specialist Solutions Architect DWH","bio":"TBD","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/trombi_2024_1744903767463001OY1t.jpg?h=93fa4828&itok=QB1AA9sz","alt":"Fabien Contaminard"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/cooking-sql-ingredients-insights-minimal-prep","alias":"\/data-ai-summit-2025\/session\/cooking-sql-ingredients-insights-minimal-prep","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.533983+00:00"}
{"id":"D25L1445","title":"Cost-Effective Data Architecture and AI Practice With Databricks at FunPlus","description":"<p>FunPlus's journey to building a cost-effective and efficient data platform with Databricks: exploring how FunPlus leveraged Databricks to tackle key challenges, enhance data engineering and ML efficiency, and showcasing best practices and their impact on game development and operations.<\/p>","track":"Data Warehousing","level":"Beginner","type":"Lightning Talk","industry":["Media and Entertainment"],"category":["AI\/BI, Databricks SQL, Unity Catalog"],"areas_of_interest":["Data Applications, Data Intelligence, Data Science, Gaming"],"delivery":["In Person"],"speakers":[{"name":"Chao Chen","company":"FunPlus","job_title":"Data Director","bio":"I have over 10 years experience of data in game industry. Currently, I serve as the Data Platform Lead at FunPlus Games, focusing on building and maintaining technical infrastructure such as data platforms, data warehouses, game operation systems, AIGC platforms, and marketing tools to support successful game publishing and operations.<br \/>\nPrior to FunPlus, I worked at NetEase Games as a Data Development Lead, where I led the planning, design, and development of data analysis products, driving multiple data-driven solutions for business success. Earlier in my career, I gained foundational experience in software development and testing at Oracle and Tencent, working on enterprise applications and quality assurance.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/pic_1743743337509001Oole.jpg?h=8a46cdc6&itok=4-Ksn0-X","alt":"Chao Chen"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"20","path":"\/session\/cost-effective-data-architecture-and-ai-practice-databricks-funplus","alias":"\/data-ai-summit-2025\/session\/cost-effective-data-architecture-and-ai-practice-databricks-funplus","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.533990+00:00"}
{"id":"D25B1668","title":"Crafting Business Brilliance: Leveraging Databricks SQL for Next-Gen Applications","description":"<p>At Haleon, we've leveraged Databricks APIs and serverless compute to develop customer-facing applications for our business. This innovative solution enables us to efficiently deliver SAP invoice and order management data through front-end applications developed and served via our API Gateway. The Databricks lakehouse architecture has been instrumental in eliminating the friction associated with directly accessing SAP data from operational systems, while enhancing our performance capabilities. Our system acheived response times of less than 3 seconds from API call, with ongoing efforts to optimise this performance. This architecture not only streamlines our data and application ecosystem but also paves the way for integrating GenAI capabilities with robust governance measures for our future infrastructure. The implementation of this solution has yielded significant benefits, including a 15% reduction in customer service costs and a 28% increase in productivity for our customer support team.<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Health and Life Sciences, Retail and CPG - Food"],"category":["Delta Lake, Databricks SQL, Unity Catalog"],"areas_of_interest":["ETL, Orchestration, SQL"],"delivery":["In Person"],"speakers":[{"name":"Wasim Ahmad","company":"Databricks","job_title":"Senior Solutions Architect","bio":null,"image":{}},{"name":"Mohammad Shalchi","company":"Haleon","job_title":"Director of Software Engineering","bio":"https:\/\/www.linkedin.com\/in\/mohammad-shalchi-a4544ba4\/","image":{}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/crafting-business-brilliance-leveraging-databricks-sql-next-gen","alias":"\/data-ai-summit-2025\/session\/crafting-business-brilliance-leveraging-databricks-sql-next-gen","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.533996+00:00"}
{"id":"D25B3154","title":"Data Intelligence for Marketing Forum: Unlocking the Future of Marketing With AI","description":"<p>Don\u2019t miss the Data Intelligence for Marketing forum at this year\u2019s Databricks Data + AI Summit \u2014 designed for marketing leaders ready to transform with data and AI. Learn how Databricks unified its marketing data with lakehouse architecture, hear Deloitte\u2019s David Geisinger on the evolving CMO role in the GenAI era, and discover how Reckitt\u2019s Bastien Parizot built a cutting-edge GenAI platform to revolutionize marketing operations. Walk away with actionable strategies, real-world blueprints, and insights from top experts to drive agility, customer insights, and AI-powered marketing success. Prioritize this forum to lead your organization\u2019s data-driven future.<\/p>","track":"Data Warehousing","level":"Beginner","type":"Breakout","industry":["Media and Entertainment, Retail and CPG - Food, Financial Services"],"category":["AI\/BI, Databricks SQL, Unity Catalog"],"areas_of_interest":["Data Intelligence, Marketing, Industry Experience"],"delivery":["In Person"],"speakers":[{"name":"Dan Morris","company":"Databricks","job_title":"Marketing Solutions GTM","bio":null,"image":{}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"180","path":"\/session\/data-intelligence-marketing-forum-unlocking-future-marketing-ai","alias":"\/data-ai-summit-2025\/session\/data-intelligence-marketing-forum-unlocking-future-marketing-ai","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534034+00:00"}
{"id":"D25B3176DBX","title":"Elevate SQL Productivity: The Power of Notebooks and SQL Editor","description":"Writing SQL is a core part of any data analyst\u2019s workflow, but small inefficiencies can add up, slowing down analysis and making it harder to iterate quickly. In this session, we\u2019ll explore our powerful features in the Databricks SQL editor and notebook that help you to be more productive when writing SQL on Databricks. We\u2019ll demo the new features and the customer use cases that inspired them. ","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX), SQL"],"delivery":["In Person"],"speakers":[{"name":"Jason Messer","company":"Databricks","job_title":"Product Manager","bio":"Jason Messer is a Product Manager on the Developer Experience team at Databricks, focusing on the Notebook and SQL editor. Before joining Databricks, Jason was one of the first software engineers at an applied AI startup, where he developed a passion for product management and creating simple, empowering products. This led him to Microsoft Azure, where gained valuable experience as he helped drive the Linux and cloud-native computing strategy as a PM. Jason holds a Computer Science degree from Brigham Young University.","image":{}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/elevate-sql-productivity-power-notebooks-and-sql-editor","alias":"\/data-ai-summit-2025\/session\/elevate-sql-productivity-power-notebooks-and-sql-editor","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534211+00:00"}
{"id":"D25B1322","title":"Empowering Healthcare Insights: A Unified Lakehouse Approach With Databricks","description":"<p>NHS England is revolutionizing healthcare research by enabling secure, seamless access to de-identified patient data through the Federated Data Platform (FDP). Despite vast data resources spread across regional and national systems, analysts struggle with fragmented, inconsistent datasets. Enter Databricks: powering a unified, virtual data lake with Unity Catalog at its core \u2014 integrating diverse NHS systems while ensuring compliance and security. By bridging AWS and Azure environments with a private exchange and leveraging the Iceberg connector to interface with Palantir, analysts gain scalable, reliable and governed access to vital healthcare data. This talk explores how this innovative architecture is driving actionable insights, accelerating research and ultimately improving patient outcomes.<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Health and Life Sciences"],"category":["Delta Lake, Data Marketplace, Delta Sharing"],"areas_of_interest":["Catalogs, Collaboration"],"delivery":["In Person"],"speakers":[{"name":"Mike Dobing","company":"Databricks","job_title":"Specialist Solutions Architect","bio":null,"image":{}},{"name":"BIANCA STRATULAT","company":"BJSS","job_title":"Databricks Solution Architect Champion","bio":"Bianca is an accomplished data leader, certified Databricks Champion, and the current Service Lead \u2013 Data (Databricks) at BJSS, where she is shaping the future of modern data platforms with a particular focus on scalable architectures, enablement, and AI integration. Passionate about data storytelling, community building, and real-world impact, she brings together a unique blend of technical expertise, strategic insight, and people-first leadership. Bianca\u2019s journey is defined by her belief that platforms are only as powerful as the stories they help us tell. She has designed, built, and deployed data products and Databricks accelerators that fast-track time to value, reduce development effort, and deliver measurable business impact.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/bianca_photo_intro_1744182839439001l5Q1.jpg?h=d0eaf9ab&itok=rEb4Q_ZA","alt":"BIANCA STRATULAT"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/empowering-healthcare-insights-unified-lakehouse-approach-databricks","alias":"\/data-ai-summit-2025\/session\/empowering-healthcare-insights-unified-lakehouse-approach-databricks","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534232+00:00"}
{"id":"D25B3180DBX","title":"Enterprise Cost Management for Data Warehousing with Databricks SQL","description":"Databricks was built as an open and unified platform to handle huge data workloads at a fraction of the cost of other solutions. This session shows you how to gain visibility into how your organization is using Databricks and where you can maximize value. Learn about the latest tools to keep your team under budget and optimize your data ROI. Find out how you can increase visibility into costs, enable attribution to internal projects, understand the Total Cost of Ownership, setup controls to avoid surprises and find ways to continually optimize your spend.","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX)"],"delivery":["In Person"],"speakers":[{"name":"Patrick Yang","company":"Databricks","job_title":"Staff Software Engineer","bio":"Computer Whisperer at Databricks, working on all things Databricks SQL","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/headshot%2520%25281%2529_1745527488963001nmGe.png?h=7b90b2bc&itok=Pbq73Mqb","alt":"Patrick Yang"}},{"name":"JooHo Yeo","company":"Databricks","job_title":"Product Manager","bio":"JooHo is a Product Manager on the Databricks SQL team, where he leads efforts to enhance warehouse management and monitoring for data platform admins. Prior to Databricks, he was a software engineer at Meta, building safe and scalable products. JooHo holds an MBA from Stanford and a B.S. in Computer Science from Cornell.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/jooho_yeo_headshot_1744829546601001ZIIX.png?h=101193d7&itok=PLNWP6n5","alt":"JooHo Yeo"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/enterprise-cost-management-data-warehousing-databricks-sql","alias":"\/data-ai-summit-2025\/session\/enterprise-cost-management-data-warehousing-databricks-sql","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534256+00:00"}
{"id":"D25B2797","title":"Geo-Powering Insights: The Art of Spatial Data Integration and Visualization","description":"<p>In this presentation, we will explore how to leverage Databricks' SQL engine to efficiently ingest and transform geospatial data. We'll demonstrate the seamless process of connecting to external systems such as ArcGIS to retrieve datasets, showcasing the platform's versatility in handling diverse data sources.<\/p><p>\u00a0<\/p><p>We'll then delve into the power of Databricks Apps, illustrating how you can create custom geospatial dashboards using various frameworks like Streamlit and Flask, or any framework of your choice. This flexibility allows you to tailor your visualizations to your specific needs and preferences.<\/p><p>\u00a0<\/p><p>Furthermore, we'll highlight the Databricks Lakehouse's integration capabilities with popular dashboarding tools such as Tableau and Power BI. This integration enables you to combine the robust data processing power of Databricks with the advanced visualization features of these specialized tools.<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Energy and Utilities, Public Sector, Retail and CPG - Food"],"category":["Databricks SQL, Unity Catalog, Databricks Apps"],"areas_of_interest":["Data Applications, Data Intelligence, SQL"],"delivery":["In Person"],"speakers":[{"name":"Mathieu Pelletier","company":"Databricks","job_title":"Specialist Solutions Architect","bio":"I am a passionate advocate for innovation and collaboration in the tech world. With a background in software development and a data engineering, I thrive on tackling challenges and turning ideas into reality.<br \/>\n<br \/>\nThroughout my career, I\u2019ve worn many hats\u2014developer, consultant, and team lead\u2014always with a focus on building strong relationships and improving myself.<br \/>\n<br \/>\nCurrently, I\u2019m a Specialist Solutions Architect @ Databricks where I\u2019m excited to leverage my skills in Geospatial to drive impactful results. When I\u2019m not coding or brainstorming, you can find me bouldering, playing tennis (sometimes pickleball), or try to the learn to play the guitar for the 5th times.<br \/>\n","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/Mathieu_Pelletier_1745589825892001wwKt.png?h=b044a8f9&itok=xYITbiRE","alt":"Mathieu Pelletier"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/geo-powering-insights-art-spatial-data-integration-and-visualization","alias":"\/data-ai-summit-2025\/session\/geo-powering-insights-art-spatial-data-integration-and-visualization","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534398+00:00"}
{"id":"D25L3178DBX","title":"Geospatial Insights With Databricks SQL: Techniques and Applications","description":"Spatial data is increasingly important, but working with it can be complex. In this session, we\u2019ll explore how Databricks SQL supports spatial analysis and helps analysts and engineers get more value from location-based data. We\u2019ll cover what\u2019s coming in the Public Preview of Spatial SQL, when and how to use the new Geometry and Geography data types, and practical use cases for H3. You\u2019ll also learn about common challenges with spatial data and how we're addressing them, along with a look at the near-term roadmap and upcoming partner integrations.","track":"Data Warehousing","level":"Intermediate","type":"Lightning Talk","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX), SQL"],"delivery":["In Person"],"speakers":[{"name":"Kent Marten","company":"Databricks","job_title":"Staff Product Manager","bio":"2 years at Databricks. Background in BI\/Analytics and GIS\/Geospatial. ","image":{}},{"name":"Michael Johns","company":"Databricks","job_title":"Lead Geospatial Product Specialist","bio":"Michael is one of the founding members of the Geospatial SME group at Databricks where he has worked with a variety of spatial data and frameworks, offered thought leadership for current geospatial direction, authored content, and spoken at numerous Databricks-sponsored events. As Geospatial Specialist Leader, he is responsible for enabling and developing a team of strong subject matter experts (SMEs). He also represents field interests with product management, marketing, and engineering to package high-quality geospatial features and field-delivered assets for our customers and partners.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/brighter_headshot_1744985495189001uU0O.png?h=ef93b635&itok=cE_MyWig","alt":"Michael Johns"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"20","path":"\/session\/geospatial-insights-databricks-sql-techniques-and-applications","alias":"\/data-ai-summit-2025\/session\/geospatial-insights-databricks-sql-techniques-and-applications","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534402+00:00"}
{"id":"D25B3184DBX","title":"How to Migrate From Oracle to Databricks SQL","description":"<p>Migrating your legacy Oracle data warehouse to the Databricks Data Intelligence Platform can accelerate your data modernization journey. In this session, learn the top strategies for completing this data migration. We will cover data type conversion, basic to complex code conversions, validation and reconciliation best practices. Discover the pros and cons of using CSV files to PySpark or using pipelines to Databricks tables. See before-and-after architectures of customers who have migrated, and learn about the benefits they realized.<\/p>","track":"Data Warehousing","level":"Beginner","type":"Breakout","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX), Migrations"],"delivery":["In Person"],"speakers":[{"name":"Laurent L\u00e9turgez","company":"Databricks","job_title":"Sr. Specialist Solutions Architect","bio":"Laurent is working as a specialist Solutions Architect specialized in Data Warehouse Migration. <br \/>\nPrior to Databricks, Laurent has worked 15 years with Oracle Databases in various roles (Developer, DBA, Architect & consultant).","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/laurent1_1744989467667001tGcV.jpg?h=96c5019e&itok=88n--_Ih","alt":"Laurent L\u00e9turgez"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/how-migrate-oracle-databricks-sql","alias":"\/data-ai-summit-2025\/session\/how-migrate-oracle-databricks-sql","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534523+00:00"}
{"id":"D25B3185DBX","title":"How to Migrate From Snowflake to Databricks SQL","description":"<p>Migrating your Snowflake data warehouse to the Databricks Data Intelligence Platform can accelerate your data modernization journey. Though a cloud platform-to-cloud platform migration should be relatively easy, the breadth of the Databricks Platform provides flexibility and hence requires careful planning and execution. In this session, we present the migration methodology, technical approaches, automation tools, product\/feature mapping, a technical demo and best practices using real-world case studies for migrating data, ELT pipelines and warehouses from Snowflake to Databricks.<\/p>","track":"Data Warehousing","level":"Beginner","type":"Breakout","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX), Migrations"],"delivery":["In Person"],"speakers":[{"name":"Koundinya Srinivasarao","company":"Databricks","job_title":"DBSQL Adoption Lead","bio":"Koundinya (\u201cKD\u201d) is a Solutions Architecture Leader at Databricks focused on driving adoption of Databricks SQL, working with customers on architecture definition and cloud strategy for Data, AI & Analytics. In his time at Databricks, he has led some of the largest implementations with a strong focus on governance and user adoption. Prior to Databricks, Koundinya had a varied career spanning DevOps, Cloud-Native Application Development, Observability Tooling and Networking at Pivotal\/VMware, Riverbed & IBM. He earned his Computer Science Bachelor\u2019s degree from Bangalore University and his Master's Degree from NC State University with a research focus in Optical Networks.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/koundinya-srinivasarao_1745850319494001Agbm.jpg?h=38ad5ba1&itok=XOORBYBU","alt":"Koundinya Srinivasarao"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/how-migrate-snowflake-databricks-sql","alias":"\/data-ai-summit-2025\/session\/how-migrate-snowflake-databricks-sql","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534526+00:00"}
{"id":"D25B3183DBX","title":"How to Migrate from Teradata to Databricks SQL","description":"<p>Storage and processing costs of your legacy Teradata data warehouses impact your ability to deliver. Migrating your legacy Teradata data warehouse to the Databricks Data Intelligence Platform can accelerate your data modernization journey. In this session, learn the top strategies for completing this data migration. We will cover data type conversion, basic to complex code conversions, validation and reconciliation best practices. How to use Databricks natively hosted LLMs to assist with migration activities. See before-and-after architectures of customers who have migrated, and learn about the benefits they realized.<\/p>","track":"Data Warehousing","level":"Beginner","type":"Breakout","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX), Migrations"],"delivery":["In Person"],"speakers":[{"name":"Mehran Golestaneh","company":"Databricks","job_title":"SSA","bio":"Over 25 years of experience in data warehousing architecture and implementation across a wide range of platforms, including IBM Balanced Warehouse, Oracle Exadata, SAP HANA, Teradata, and Databricks. Previously employed by Teradata for 7 Years and 8 years of independant consulting.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/My%2520Headshot_1744839965513001pJMS.jpg?h=a5884086&itok=Hr6UG9yu","alt":"Mehran Golestaneh"}},{"name":"Fabien Contaminard","company":"Databricks","job_title":"Sr. Specialist Solutions Architect DWH","bio":"TBD","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/trombi_2024_1744903767463001OY1t.jpg?h=93fa4828&itok=QB1AA9sz","alt":"Fabien Contaminard"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/how-migrate-teradata-databricks-sql","alias":"\/data-ai-summit-2025\/session\/how-migrate-teradata-databricks-sql","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534530+00:00"}
{"id":"D25B1238","title":"HP's Data Platform Migration Journey: Redshift to Lakehouse","description":"<p>HP Print's data platform team took on a migration from a monolithic, shared resource of AWS Redshift, to a modular and scalable data ecosystem on Databricks lakehouse.\u200b<\/p><p>\u00a0<\/p><p>The result was 30\u201340% cost savings, scalable and isolated resources for different data consumers and ETL workloads, and performance optimization for a variety of query types.\u200b<\/p><p>\u00a0<\/p><p>Through this migration, there were technical challenges and learnings relating to the ETL migrations with DBT, new Databricks features like Liquid Clustering, predictive optimization, Photon, SQL serverless warehouses, managing multiple teams on Unity Catalog, and others.\u200b<\/p><p>\u00a0<\/p><p>This presentation dives into both the business and technical sides of this migration. Come along as we share our key takeaways from this journey.\u200b<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Manufacturing"],"category":["Delta Lake, Databricks SQL, Unity Catalog"],"areas_of_interest":["Customer Data Platform, Migrations, SQL"],"delivery":["In Person"],"speakers":[{"name":"Isaac Chan","company":"HP Inc.","job_title":"Data Engineer","bio":"Isaac Chan is a lead data engineer at HP Inc., focused on data architecture and strategy to enable businesses to deliver insights on HP products like software applications and consumer\/enterprise hardware. Isaac has led large platform migrations to Databricks from end-to-end and develops robust pipelines to solve various business priorities. Outside of work, Isaac is a competitive golfer.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/Image_1746146067529001q7q9.jpg?h=c6edb48f&itok=c1-vE7KX","alt":"Isaac Chan"}},{"name":"Kavya Atmakuri","company":"HP Inc.","job_title":"Data Engineer","bio":"Kavya is a lead data engineer at HP Inc.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/Kavya2025_1746140648992001jZt2.jpg?h=86d1f598&itok=-35ctHAB","alt":"Kavya Atmakuri"}}],"day":"Thursday","room":"South, Level 3, Room 305","starts":"2025-06-12T19:40:00","ends":"2025-06-12T20:20:00","starts_pst":"2025-06-12T12:40:00","ends_pst":"2025-06-12T13:20:00","start_time":"7:40 pm","end_time":"8:20 pm","pst_start_time":"12:40 pm","pst_end_time":"1:20 pm","duration":"40","path":"\/session\/hps-data-platform-migration-journey-redshift-lakehouse","alias":"\/data-ai-summit-2025\/session\/hps-data-platform-migration-journey-redshift-lakehouse","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534540+00:00"}
{"id":"D25L2709","title":"Improving User Experience and Efficiency Using DBSQL","description":"<p>To scale Databricks SQL to 2,000 users efficiently and cost-effectively, we adopted serverless, ensuring dynamic scalability and resource optimization. During peak times, resources scale up automatically; during low demand, they scale down, preventing waste.<\/p><p>\u00a0<\/p><p>Additionally, we implemented a strong content governance model. We created continuous monitoring to assess query and dashboard performance, notifying users about adjustments and ensuring only relevant content remains active. If a query exceeds time or impact limits, access is reviewed and, if necessary, deactivated.<\/p><p>\u00a0<\/p><p>This approach brought greater efficiency, cost reduction and an improved user experience, keeping the platform well-organized and high-performing.<\/p>","track":"Data Warehousing","level":"Beginner","type":"Lightning Talk","industry":["Enterprise Technology, Professional Services, Financial Services"],"category":["AI\/BI, Databricks SQL, Unity Catalog"],"areas_of_interest":["Customer Data Platform"],"delivery":["In Person"],"speakers":[{"name":"Renato Suarez","company":"PicPay","job_title":"Data Platform Manager","bio":"Renato Suarez Moreira is a data professional with over 17 years of experience, specializing in the governance, management, and optimization of data platforms at scale. He currently leads the Data Platform team at PicPay, one of the largest digital banks in Brazil.<br \/>\n<br \/>\nHis work is marked by the modernization of data environments, cloud infrastructure cost optimization, and the promotion of a data-driven culture that empowers people to use data independently and grow professionally. Renato is a strong advocate for the strategic and responsible use of data as a driver of innovation and organizational impact.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/20190606_103754%257E2_1744855836560001p7ld.jpg?h=22719306&itok=swgND6XM","alt":"Renato Suarez"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"20","path":"\/session\/improving-user-experience-and-efficiency-using-dbsql","alias":"\/data-ai-summit-2025\/session\/improving-user-experience-and-efficiency-using-dbsql","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534561+00:00"}
{"id":"D25B3173DBX","title":"Introduction to Databricks SQL ","description":"If you are brand new to Databricks SQL and want to get a lightning tour of this intelligent data warehouse, this session is for you. Learn about the architecture of Databricks SQL. Then show how simple, streamlined interfaces are making it easier for analysts, developers, admins and business users to get their jobs done and questions answered. We\u2019ll show how easy it is to create a warehouse, get data, transform it and build queries and dashboards. By the end of the session, you\u2019ll be able to build a Databricks SQL warehouse in 5 minutes. ","track":"Data Warehousing","level":"Beginner","type":"Breakout","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX), Getting started with Databricks"],"delivery":["In Person"],"speakers":[{"name":"Pearl Ubaru","company":"Databricks","job_title":"Technical Product Marketing Engineer","bio":"I am an ex-high school math teacher turned data scientist with skills in data analytics, data warehousing and data governance.","image":{}},{"name":"Himanshu Raja","company":"Databricks","job_title":"Director, Product Management, Databricks","bio":"Himanshu Raja is a Sr. Manager of Product at Databricks helping customers build open, scalable, and performant analytics systems. Himanshu holds an MBA from NYU Stern School of Business and MS in Photonics from University of St Andrews, UK. Prior to joining Databricks, Himanshu was at Amazon Redshift and helped build the world\u2019s largest cloud data warehouse.","image":{}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/introduction-databricks-sql","alias":"\/data-ai-summit-2025\/session\/introduction-databricks-sql","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534603+00:00"}
{"id":"D25B2639","title":"Migrating Legacy SAS Code to Databricks Lakehouse: What We Learned Along the Way","description":"<p>In PacificSource Health Plans, a health insurance company in the US, we are on a successful multi-year journey to migrate all of our data and analytics ecosystem to Databricks Enterprise Data Warehouse (lakehouse).<\/p><p>\u00a0<\/p><p>A particular obstacle on this journey was a reporting data mart which relied on copious amounts of legacy SAS code that applied sophisticated business logic transformations for membership, claims, premiums and reserves. This core data mart was driving many of our critical reports and analytics.<\/p><p>\u00a0<\/p><p>In this session we will share the unique and somewhat unexpected challenges and complexities we encountered in migrating this legacy SAS code. How our partner (T1A) leveraged automation technology (Alchemist) and some unique approaches to reverse engineer (analyze), instrument, translate, migrate, validate and reconcile these jobs; and what lessons we learned and carried from this migration effort.<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Financial Services"],"category":["Apache Spark, Delta Lake, Unity Catalog"],"areas_of_interest":["ETL, Migrations"],"delivery":["In Person"],"speakers":[{"name":"Dmitriy Alergant","company":"Tier One Analytics Inc.","job_title":"Principal Architect","bio":"Dmitriy is a passionate Data and Analytics, BI, and Data Warehousing leader with nearly 20 years of experience in professional services as a Solution Architect and Tech Lead in Modern Enterprise Cloud Architecture and Data Integration.<br \/>\n<br \/>\nDmitriy is a certified Databricks Partner Solutions Champion and Data Engineer Professional.<br \/>\n<br \/>\nEarlier in his career, Dmitriy used to be a SAS architect implementing and optimizing SAS solutions for clients, until this became a dead-end technology. Dmitriy and T1A then pivoted to helping former SAS clients get out of it to Databricks.<br \/>\n<br \/>\nAs an expert and practitioner in both SAS and Databricks, Dmitriy helped shape the vision and design of T1A's \"Alchemist\" solution accelerator for SAS to Databricks migrations.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/da_t1a_1745559050710001nbmo.jpg?h=41f8cf6d&itok=C6b9lJJa","alt":"Dmitriy Alergant"}},{"name":"Matt Adams","company":"PacificSource Health Plans","job_title":"Senior Data Platforms Developer","bio":"A proud owner of three cats, Matt Adams has worked in IT for over a decade. He works at PacificSource Health Plans in Eugene, Oregon on the Data Platforms team, and led the implementation of Databricks and the Delta Lakehouse.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/e2443_LThumb_1744067633071001Edzr.jpg?h=6c83441f&itok=YVo40UP_","alt":"Matt Adams"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/migrating-legacy-sas-code-databricks-lakehouse-what-we-learned-along","alias":"\/data-ai-summit-2025\/session\/migrating-legacy-sas-code-databricks-lakehouse-what-we-learned-along","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534789+00:00"}
{"id":"D25L3192DBX","title":"Multi-Statement Transactions: How to Improve Data Consistency and Performance","description":"<p>Multi-statement transactions bring the atomicity and reliability of traditional databases to modern data warehousing on the lakehouse. In this session, we\u2019ll explore real-world patterns enabled by multi-statement transactions \u2014 including multi-table updates, deduplication pipelines and audit logging \u2014 and show how Databricks ensures atomicity and consistency across complex workflows. We\u2019ll also dive into demos and share tips to getting started and migrations with this feature in Databricks SQL.<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Lightning Talk","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX), Migrations, SQL"],"delivery":["In Person"],"speakers":[{"name":"Franco Patano","company":"Databricks","job_title":"Principal Solutions Architect","bio":null,"image":{}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"20","path":"\/session\/multi-statement-transactions-how-improve-data-consistency-and","alias":"\/data-ai-summit-2025\/session\/multi-statement-transactions-how-improve-data-consistency-and","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534818+00:00"}
{"id":"D25B2019","title":"Our Journey to Operations Excellence (FinOps, Observability)","description":"<p>As data platforms scale, managing costs and ensuring system reliability become increasingly complex. Achieving operational excellence requires a strategic approach to FinOps (Cloud Cost Optimization) and Observability (End-to-End Monitoring).<\/p><p>\u00a0<\/p><p>In this session, we\u2019ll share our journey in:<\/p><ul>\t<li>Implementing FinOps practices to drive cloud cost efficiency and accountability<\/li>\t<li>Building observability frameworks for real-time insights into data workloads<\/li>\t<li>Balancing performance, reliability and cost through proactive monitoring<\/li>\t<li>Leveraging automation and governance to optimize resource allocation<\/li><\/ul>","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Enterprise Technology, Professional Services"],"category":["Unity Catalog"],"areas_of_interest":["Developer Experience"],"delivery":["In Person"],"speakers":[{"name":"Karthikeya Chennuru","company":"WarnerBros Discovery","job_title":"Sr.Manager, Software Engineering","bio":null,"image":{}},{"name":"Ravi Tata","company":"WBD","job_title":null,"bio":null,"image":{}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/our-journey-operations-excellence-finops-observability","alias":"\/data-ai-summit-2025\/session\/our-journey-operations-excellence-finops-observability","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534859+00:00"}
{"id":"D25B3179DBX","title":"Performance Best Practices for Fast Queries, High Concurrency, and Scaling on Databricks SQL","description":"<p>Data warehousing in enterprise and mission-critical environments needs special consideration for price\/performance and security. This session will explain how Databricks SQL addresses the most challenging requirements for high-concurrency, low-latency performance and managing user identity, access and governance at scale. We will also cover the latest advancements in resource-based scheduling, autoscaling and caching enhancements that allow for seamless performance and workload management.<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX)"],"delivery":["In Person"],"speakers":[{"name":"Jeremy Lewallen","company":"Databricks","job_title":"Product Manager","bio":"Jeremy Lewallen is a Staff Product Manager on DBSQL. He leads the Performance, Gateway, and API teams.","image":{}},{"name":"Mostafa Mokhtar","company":"Databricks","job_title":"Principal Software Engineer","bio":null,"image":{}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/performance-best-practices-fast-queries-high-concurrency-and-scaling","alias":"\/data-ai-summit-2025\/session\/performance-best-practices-fast-queries-high-concurrency-and-scaling","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534880+00:00"}
{"id":"D25L2208","title":"Pushing the Limits of What Your Warehouse Can Do Using Python and Databricks","description":"SQL warehouses in Databricks can run more than just SQL. Join this session to learn how to get more out of your SQL warehouses and any tools built on top of it by leveraging Python. After attending this session, you will be familiar with Python user-defined functions and how to bring in custom dependencies from PyPi, as a custom wheel or even securely invoke cloud services with performance at scale. ","track":"Data Warehousing","level":"Beginner","type":"Lightning Talk","industry":["Health and Life Sciences, Media and Entertainment, Financial Services"],"category":["Databricks SQL, Unity Catalog"],"areas_of_interest":["Data Applications, Getting started with Databricks, SQL"],"delivery":["In Person"],"speakers":[{"name":"Jakob Mund","company":"Databricks","job_title":"Staff Product Manager","bio":"Jakob is part of the product team at Databricks working closely with the engineering teams on secure and extensible compute in Unity Catalog and across the Lakehouse. Favorite topics include Python UDFs, DBSQL extensibility and Unity catalog clusters. Prior to Databricks, Jakob worked at Tableau's data platform build on the Hyper extract engine. ","image":{}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"0","path":"\/session\/pushing-limits-what-your-warehouse-can-do-using-python-and-databricks","alias":"\/data-ai-summit-2025\/session\/pushing-limits-what-your-warehouse-can-do-using-python-and-databricks","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534914+00:00"}
{"id":"D25B1931","title":"Revolutionizing Banking Data, Analytics and AI: Building an Enterprise Data Hub With Databricks","description":"<p>Explore the transformative journey of a regional bank as it modernizes its enterprise data infrastructure amidst the challenges of legacy systems and past mergers and acquisitions. The bank is creating an Enterprise Data Hub using Deloitte's industry experience and the Databricks Data Intelligence Platform to drive growth, efficiency and Large Financial Institution readiness needs. This session will showcase how the new data hub will be a one-stop-shop for LOB and enterprise needs, while unlocking the advanced analytics and GenAI possibilities. Discover how this initiative is going to empower the ambitions of a regional bank to realize their \u201cbig bank muscle, small bank hustle.\u201d<\/p>","track":"Data Warehousing","level":"Advanced","type":"Breakout","industry":["Financial Services"],"category":["Delta Lake, Unity Catalog"],"areas_of_interest":["Data Ingestion, Generative AI (LLMs), Migrations"],"delivery":["In Person"],"speakers":[{"name":"Shailender Sidhu","company":"Deloitte","job_title":"Principal","bio":"Shailender is a leader in Deloitte Consulting's Financial Services Industry AI & Engineering practice. He works with US and Global financial services institutions to deliver and advise on large scale enterprise AI & Data driven transformations and change agenda. He supports line of business leaders across the financial services industry segments to drive growth, regulatory, compliance and efficiency agenda. ","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/SSS_1745982505259001fri2.jpg?h=ef775988&itok=qKziyo2c","alt":"Shailender Sidhu"}},{"name":"Mohan Sankararaman","company":"First Horizon Bank","job_title":"Chief Information Officer","bio":"Mohan Sankararaman is executive vice president and chief information officer for First Horizon Corporation. Sankararaman joined the company in 2009 and has served in his current role since 2020. Prior to this role, he was director of strategic initiatives, leading efforts with a focus on executional excellence and managing the day-to-day activities for several mergers and acquisitions to ensure a smooth integration, conversion, and transition for the bank\u2019s clients and associates.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/MohanSankararaman_1738518347733001arvi.jpg?h=fbf7a813&itok=TEURyWc1","alt":"Mohan Sankararaman"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/revolutionizing-banking-data-analytics-and-ai-building-enterprise-data","alias":"\/data-ai-summit-2025\/session\/revolutionizing-banking-data-analytics-and-ai-building-enterprise-data","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.534990+00:00"}
{"id":"D25B1511","title":"Revolutionizing PepsiCo BI Capabilities: From Traditional BI to Next-Gen Analytics Powerhouse ","description":"<p>This session will provide an in-depth overview of how PepsiCo, a global leader in food and beverage, transformed its outdated data platform into a modern, unified and centralized data and AI-enabled platform using the Databricks SQL serverless environment. Through three distinct implementations that transpired at PepsiCo in 2024, we will demonstrate how the PepsiCo Data Analytics & AI Group unlocked pivotal capabilities that facilitated the delivery of diverse data-driven insights to the business, reduced operational expenses and enhanced overall performance through the newly implemented platform.\u00a0<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Retail and CPG - Food"],"category":["AI\/BI, Databricks SQL, Unity Catalog"],"areas_of_interest":["Data Applications, Data Intelligence, Migrations"],"delivery":["In Person"],"speakers":[{"name":"Joshua Sayah Lee","company":"PepsiCo Inc.","job_title":"Lead Global D&AI Solution Architect","bio":"Since 2008, Joshua Lee has taken on various roles at PepsiCo within the Data and AI areas and currently serves as the Lead Global Data Analytics and AI Solution Architect. In this role, he is responsible for designing Data Analytics and AI solutions that enhance business results. His key duties include advising on data initiatives, advancing AI capabilities, managing solution implementation, supporting data strategies, mentoring developers, training the analytics team, and staying updated with industry trends.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/IMG_2217_1744059835153001EGlk.jpg?h=7f412c8f&itok=bKHlsmdu","alt":"Joshua Sayah Lee"}},{"name":"John Abraham","company":"PepsiCo","job_title":"Director, Data Services","bio":null,"image":{}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/revolutionizing-pepsico-bi-capabilities-traditional-bi-next-gen","alias":"\/data-ai-summit-2025\/session\/revolutionizing-pepsico-bi-capabilities-traditional-bi-next-gen","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.535017+00:00"}
{"id":"D25B1327","title":"Self-Service Assortment and Space Analytics at Walmart Scale","description":"<p>Assortment and space analytics optimizes product selection and shelf allocation to boost sales, improve inventory management and enhance customer experience. However, challenges like evolving demand, data accuracy and operational alignment hinder success. Older approaches struggled due to siloed tools, slow performance and poor governance.<\/p><p>\u00a0<\/p><p>Databricks unified platform resolved these issues, enabling seamless data integration, high-performance analytics and governed sharing. The innovative AI\/BI Genie interface empowered self-service analytics, driving non-technical user adoption.<\/p><p>\u00a0<\/p><p>This solution helped Walmart cut time to value by 90% and saved $5.6M annually in FTE hours leading to increased productivity.<\/p><p>\u00a0<\/p><p>Looking ahead, AI agents will let store managers and merchants execute decisions via conversational interfaces, streamlining operations and enhancing accessibility. This transformation positions retailers to thrive in a competitive, customer-centric market.<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Retail and CPG - Food"],"category":["AI\/BI, Databricks SQL, Unity Catalog"],"areas_of_interest":["AI Agents, Data Intelligence, Data Science"],"delivery":["In Person"],"speakers":[{"name":"Alexandro Arreola-Garcia","company":"Walmart","job_title":"Senior Manager, Assortment & Space","bio":"Alexandro Arreola-Garcia is a Senior Manager of Merchandising Transformation at Walmart, where he leads assortment and space analytics initiatives. With expertise in big data technologies and cloud platforms, he leverages Apache Spark, Python, and interactive R Shiny applications to drive data-informed merchandising decisions and deliver insights through custom web dashboards.<br \/>\n<br \/>\nHis background combines retail analytics, data engineering, and full-stack development, having progressed from roles in global sourcing and business analysis to leading large-scale data transformation projects. Alexandro holds an MS in Business Analytics from SMU Cox School of Business and brings extensive experience with enterprise data tools including Google BigQuery, Apache Spark, and machine learning applications.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/Alexandro%2520Pic_1738082337506001f3LP.jpg?h=a7ffc51c&itok=GxbVlAg9","alt":"Alexandro Arreola-Garcia"}},{"name":"Nikit Shah","company":"Databricks","job_title":"Sr. Delivery Solutions Architect","bio":"Nikit is a Sr. Delivery Solutions Architect at Databricks with over 14 years of client-facing experience in designing and delivering enterprise level solutions. Driven to solve client problems using transformative technologies such as AI \/ natural language processing, cutting-edge cloud-based services to create innovative and efficient solutions for multiple industry verticals, having currently worked across Retail, Financial Services, Telecommunications, and Automotive industries.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/nikit_profile_pic_1740771895498001Vizc.png?h=a7e6d17b&itok=OgH1DcGq","alt":"Nikit Shah"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/self-service-assortment-and-space-analytics-walmart-scale","alias":"\/data-ai-summit-2025\/session\/self-service-assortment-and-space-analytics-walmart-scale","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.535159+00:00"}
{"id":"D25B2536","title":"Smashing Silos, Shaping the Future: Data for All in the Next-Gen Ecosystem","description":"<p>A successful data strategy requires the right platform and the ability to empower the broader user community by creating simple, scalable and secure patterns that lower the barrier to entry while ensuring robust data practices. Guided by the belief that everyone is a data person, we focus on breaking down silos, democratizing access and enabling distributed teams to contribute through a federated \"data-as-a-product\" model. We\u2019ll share the impact and lessons learned in creating a single source of truth on Unity Catalog, consolidated from diverse sources and cloud platforms. We\u2019ll discuss how we streamlined governance with Databricks Apps, Workflows and native capabilities, ensuring compliance without hindering innovation. We\u2019ll also cover how we maximize the value of that catalog by leveraging semantics to enable trustworthy, AI-driven self-service in AI\/BI dashboards and downstream apps. Come learn how we built a next-gen data ecosystem that empowers everyone to be a data person.<\/p>","track":"Data Warehousing","level":"Beginner","type":"Breakout","industry":["Education, Enterprise Technology, Retail and CPG - Food"],"category":["Databricks Workflows, Unity Catalog, Databricks Apps"],"areas_of_interest":["Catalogs, Collaboration, Security & Compliance"],"delivery":["In Person"],"speakers":[{"name":"Michael Flynn","company":"Rivian Volkswagen Group Technology","job_title":"Director, Core Data","bio":"--","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/IMG_2729_1744300086892001qgmO.jpg?h=fe453086&itok=SPRyTNaJ","alt":"Michael Flynn"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/smashing-silos-shaping-future-data-all-next-gen-ecosystem","alias":"\/data-ai-summit-2025\/session\/smashing-silos-shaping-future-data-all-next-gen-ecosystem","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.535224+00:00"}
{"id":"D25L2261","title":"Spark Right-Sizing: The Secret to Saving Millions of Dollars at LinkedIn","description":"<p>At LinkedIn, we manage over 400,000 daily Spark applications consuming 200+ PBHrs of compute daily. To address the challenges posed by manual configuration of Spark's memory tuning options, which led to low memory utilization and frequent OOM errors, we developed an automated Spark executor memory right-sizing system. Our approach, utilizing a policy-based system with nearline and real-time feedback loops, automates memory tuning, leading to more efficient resource allocation, improved user productivity and increased job reliability. By leveraging historical data and real-time error classification, we dynamically adjust memory, significantly narrowing the gap between allocated and utilized resources while reducing failures. This initiative has achieved a 13% increase in memory utilization and a 90% drop in OOM-related job failures, saving us 1000s of PBHrs of compute every year.<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Lightning Talk","industry":["Enterprise Technology, Media and Entertainment"],"category":["Apache Spark"],"areas_of_interest":["AI Agents, Developer Experience, Open Source"],"delivery":["In Person"],"speakers":[{"name":"Shreyesh Arangath","company":"LinkedIn","job_title":"Senior Software Engineer","bio":"Shreyesh is a Senior Software Engineer, focused on developing Apache Spark and Big Data Infrastructure at LinkedIn","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/IMG_5936_1738607025702001Mad2.JPG?h=7208460a&itok=kyj_Mlqv","alt":"Shreyesh Arangath"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"20","path":"\/session\/spark-right-sizing-secret-saving-millions-dollars-linkedin","alias":"\/data-ai-summit-2025\/session\/spark-right-sizing-secret-saving-millions-dollars-linkedin","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.535252+00:00"}
{"id":"D25L3366SPO","title":"Sponsored by: Capital One Software | How Capital One Balances Lower Cost and Peak Performance in Databricks","description":"<p>Companies need a lot of data to build and deploy AI models\u2014and they want it quickly. To meet this demand, platform teams are quickly scaling their Databricks usage, resulting in excess cost driven by inefficiencies and performance anomalies. Capital One has over 4,000 users leveraging Databricks to power advanced analytics and machine learning capabilities at scale. In this talk, we\u2019ll share lessons learned from optimizing our own Databricks usage while balancing lower cost with peak performance. Attendees will learn how to identify top sources of waste, best practices for cluster management, tips for user governance and methods to keep costs in check.<\/p>","track":"Data Warehousing","level":"Intermediate","type":"Lightning Talk","industry":["Enterprise Technology, Health and Life Sciences, Financial Services"],"category":["Databricks SQL"],"areas_of_interest":["SQL, Thought Leadership"],"delivery":["In Person"],"speakers":[],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"0","path":"\/session\/sponsored-capital-one-software-how-capital-one-balances-lower-cost-and","alias":"\/data-ai-summit-2025\/session\/sponsored-capital-one-software-how-capital-one-balances-lower-cost-and","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.535268+00:00"}
{"id":"D25B2885","title":"SQL-Based ETL: Options for SQL-Only Databricks Development","description":"<p>Using SQL for data transformation is a powerful way for an analytics team to create their own data pipelines. However, relying on SQL often comes with tradeoffs such as limited functionality, hard-to-maintain stored procedures or skipping best practices like version control and data tests. Databricks supports building high-performing SQL ETL workloads. Attend this session to hear how Databricks supports SQL for data transformation jobs as a core part of your Data Intelligence Platform.<\/p><p>\u00a0<\/p><p>In this session we will cover 4 options to use Databricks with SQL syntax to create Delta tables:<\/p><ul>\t<li>DLT: A declarative ETL option to simplify batch and streaming pipelines<\/li>\t<li>dbt: An open-source framework to apply engineering best practices to SQL based data transformations<\/li>\t<li>SQLMesh: an open-core product to easily build high-quality and high-performance data pipelines<\/li>\t<li>SQL notebooks jobs: a combination of Databricks Workflows and parameterized SQL notebooks<\/li><\/ul>","track":"Data Warehousing","level":"Beginner","type":"Breakout","industry":["Enterprise Technology, Health and Life Sciences, Financial Services"],"category":["Databricks SQL, DLT, LakeFlow"],"areas_of_interest":["ETL, Migrations, SQL"],"delivery":["In Person"],"speakers":[{"name":"Dustin Vannoy","company":"Databricks","job_title":"Sr. Specialist Solutions Architect","bio":"Dustin Vannoy is a data engineer and solutions architect experienced in solving business problems with analytics and big data solutions. He is passionate about all aspects of data engineering, especially building data platforms and streaming data pipelines. He is experienced in using cloud technologies to transition legacy ETL jobs into a modern lakehouse architecture. He currently focuses on guiding others to build successful data platforms and pipelines with Databricks, Apache Spark, Azure, Apache Kafka, Python, and Scala.<br \/>\nHe is co-founder of the Data Engineering San Diego meetup and encourages others to grow their data skills by making mentoring others, speaking at events and creating tutorials at YouTube\/DustinVannoy.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/Dustin.Vannoy_1744175146585001Ej7v.PNG?h=cd2a7045&itok=6uGszvDr","alt":"Dustin Vannoy"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/sql-based-etl-options-sql-only-databricks-development","alias":"\/data-ai-summit-2025\/session\/sql-based-etl-options-sql-only-databricks-development","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.535329+00:00"}
{"id":"D25L1246","title":"The JLL Training and Upskill Program for Our Warehouse Migration to Databricks","description":"<p>Databricks Odyssey is JLL\u2019s bespoke training program designed to upskill and prepare data professionals for a new world of data lakehouse. Based on the concepts of learn, practice and certify, participants earn points, moving through five levels by completing activities with business application of Databricks key features. Databricks Odyssey facilitates cloud data warehousing migration by providing best practice frameworks, ensuring efficient use of pay-per-compute platforms. JLL\/T Insights and Data fosters a data culture through learning programs that develop in-house talent and create career pathways.<\/p><p>\u00a0<\/p><p>Databricks Odyssey offers:<\/p><ul>\t<li>JLL-specific hands-on learning<\/li>\t<li>Gamified 'level up' approach<\/li>\t<li>Practical, applicable skills<\/li><\/ul><p>\u00a0<\/p><p>Benefits include:<\/p><ul>\t<li>Improved platform efficiency<\/li>\t<li>Enhanced data accuracy and client insights<\/li>\t<li>Ongoing professional development<\/li>\t<li>Potential cost savings through better utilization<\/li><\/ul>","track":"Data Warehousing","level":"Beginner","type":"Lightning Talk","industry":["Professional Services"],"category":["Delta Lake, Databricks SQL, Unity Catalog"],"areas_of_interest":["Collaboration, Getting started with Databricks, Thought Leadership"],"delivery":["In Person"],"speakers":[{"name":"Kristopher Curtis","company":"JLL","job_title":"Global Technology Director","bio":"Kris Curtis is an accomplished professional with a wealth of experience in the field of Business Intelligence (BI). With a successful track record in leading analytics teams and deploying cutting-edge software and technology, Kris has a deep understanding of delivering valuable insights to businesses. At JLL, Kris plays a pivotal role in bridging the gap between BI teams and data platforms, operating across hierarchies and regions. With a strong focus on best practices and governance, Kris ensures the optimization of both BI and IT processes, resulting in increased efficiencies and cost savings throughout infrastructure and licensing.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/Kris%2520Curtis_head_1746154438203001Uwfh.jpg?h=5ca1baf1&itok=Q6F5FlBd","alt":"Kristopher Curtis"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"20","path":"\/session\/jll-training-and-upskill-program-our-warehouse-migration-databricks","alias":"\/data-ai-summit-2025\/session\/jll-training-and-upskill-program-our-warehouse-migration-databricks","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.535440+00:00"}
{"id":"D25B2121","title":"Unifying Data Delivery: Using Databricks as Your Enterprise Serving Layer","description":"<p>This session will take you on our journey of integrating Databricks as the core serving layer in a large enterprise, demonstrating how you can build a unified data platform that meets diverse business needs.<\/p><p>\u00a0<\/p><p>We will walk through the steps for constructing a central serving layer by leveraging Databricks\u2019 SQL Warehouse to efficiently deliver data to analytics tools and downstream applications. To tackle low latency requirements, we\u2019ll show you how to incorporate an interim scalable relational database layer that delivers sub-second performance for hot data scenarios. Additionally, we\u2019ll explore how Delta Sharing enables secure and cost-effective data distribution beyond your organization, eliminating silos and unnecessary duplication for a truly end-to-end centralized solution.<\/p><p>\u00a0<\/p><p>This session is perfect for data architects, engineers and decision-makers looking to unlock the full potential of Databricks as a centralized serving hub.<\/p>","track":"Data Warehousing","level":"Advanced","type":"Breakout","industry":["Enterprise Technology, Public Sector"],"category":["Data Marketplace, Delta Sharing, Unity Catalog"],"areas_of_interest":["Collaboration, Customer Data Platform, Migrations"],"delivery":["In Person"],"speakers":[{"name":"Ivan Spiriev","company":"The World Bank","job_title":"Data Platform Architect","bio":"Ivan is a Data Platform Architect at the World Bank Group and a certified Databricks Platform Architect. Passionate about data and knowledge sharing, he has extensive experience designing and implementing enterprise data solutions, with a particular focus on cloud-native analytics platforms. He specializes in migrating on-premises solutions to the cloud and fine-tuning Databricks environments, ensuring robust, scalable, and efficient data architectures for modern enterprises.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/PictureIS3_1738593873165001K8vI.jpg?h=656eaa10&itok=4yWjt97x","alt":"Ivan Spiriev"}},{"name":"Ivan Donev","company":"The World Bank","job_title":"Data Platform Architect","bio":"Ivan Donev is a Data Platform Architect at the World Bank Group and a MVP Alumni. He is a certified Microsoft Expert and Trainer since 2015. Ivan is passionate about data, knowledge sharing and has experience in setting up large enterprise data solutions, ranging from on-prem Application and Datawarehouse databases, to modern, cloud-native analytics platforms to manage the wealth of data every organization has.","image":{"url":"https:\/\/microsites.databricks.com\/sites\/default\/files\/styles\/headshot\/public\/media\/images\/dataaisummit_speaker\/Image_1738594799089001BSey.jpg?h=f103bc5f&itok=ww_OS1FY","alt":"Ivan Donev"}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/unifying-data-delivery-using-databricks-your-enterprise-serving-layer","alias":"\/data-ai-summit-2025\/session\/unifying-data-delivery-using-databricks-your-enterprise-serving-layer","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.535658+00:00"}
{"id":"D25B3186DBX","title":"What\u2019s New in Databricks SQL: Latest Features and Live Demos","description":"Databricks SQL has added significant features in the last year at a fast pace. This session will share the most impactful features and the customer use cases that inspired them. We will highlight the new SQL editor, SQL coding features, streaming tables and materialized views, BI integrations, cost management features, system tables and observability features, and more. We will also share AI-powered performance optimizations.","track":"Data Warehousing","level":"Intermediate","type":"Breakout","industry":["Enterprise Technology"],"category":["Databricks SQL"],"areas_of_interest":["Databricks Experience (DBX)"],"delivery":["In Person"],"speakers":[{"name":"Kent Marten","company":"Databricks","job_title":"Staff Product Manager","bio":"2 years at Databricks. Background in BI\/Analytics and GIS\/Geospatial. ","image":{}},{"name":"Gaurav Saraf","company":null,"job_title":"Sr Staff Product Manager","bio":"Gaurav is a Product Manager for Databricks SQL Warehouses. ","image":{}}],"day":"","room":"","starts":null,"ends":null,"starts_pst":"","ends_pst":"","start_time":"","end_time":"","pst_start_time":"","pst_end_time":"","duration":"40","path":"\/session\/whats-new-databricks-sql-latest-features-and-live-demos","alias":"\/data-ai-summit-2025\/session\/whats-new-databricks-sql-latest-features-and-live-demos","slides":null,"video":null,"scraped_at":"2025-05-02T15:15:21.535786+00:00"}
